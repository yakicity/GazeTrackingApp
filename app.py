import json
import math
import time
from datetime import datetime
from typing import Dict, Tuple, List, Optional

import av
import cv2
import mediapipe as mp
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
from fpdf import FPDF
import os
import io
from PIL import Image, ImageDraw, ImageFont

# ================= è¦–ç·šæ¨å®šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =================
class GazeEstimator:
    """
    MediaPipeã®Face Meshã‚’ä½¿ç”¨ã—ã¦è¦–ç·šã‚’æ¨å®šã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã‚‚å«ã‚€ã€‚
    """

    # MediaPipeã®Face Meshãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    LEFT_EYE = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]
    RIGHT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]
    LEFT_IRIS = [474, 475, 476, 477, 468, 469, 470, 471, 472]
    RIGHT_IRIS = [469, 470, 471, 472, 473, 474, 475, 476, 477]

    def __init__(self, det_conf=0.5, trk_conf=0.5):
        """MediaPipe FaceMeshãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–"""
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,  # è™¹å½©ï¼ˆIRISï¼‰ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã«True
            min_detection_confidence=det_conf,
            min_tracking_confidence=trk_conf,
        )

        # --- ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ‡ãƒ¼ã‚¿ ---
        self.rx_left: Optional[float] = None
        self.rx_right: Optional[float] = None
        self.ry_top: Optional[float] = None
        self.ry_bottom: Optional[float] = None
        self.offx_px: float = 0.0
        self.offy_px: float = 0.0
        self.calibrated: bool = False
        self.base_w: Optional[int] = None
        self.base_h: Optional[int] = None

    @staticmethod
    def _center(landmarks, idxs):
        """æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ç¾¤ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—ã™ã‚‹"""
        pts = np.array([[landmarks[i].x, landmarks[i].y] for i in idxs if i < len(landmarks)])
        if len(pts) == 0:
            return None
        return pts.mean(axis=0)

    def _iris_center_circle_px(self, landmarks, indices, w, h):
        """è™¹å½©ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ç¾¤ã«æœ€å°å¤–æ¥å††ã‚’ã‚ã¦ã¯ã‚ã€ãã®ä¸­å¿ƒåº§æ¨™ï¼ˆãƒ”ã‚¯ã‚»ãƒ«å˜ä½ï¼‰ã‚’è¿”ã™"""
        pts = [(landmarks[i].x * w, landmarks[i].y * h) for i in indices if i < len(landmarks)]
        if len(pts) < 3:
            return None
        pts_np = np.array(pts, dtype=np.float32)
        (cx, cy), _ = cv2.minEnclosingCircle(pts_np)
        return (cx, cy)

    def set_calibration_values(
        self,
        rx_left: float, rx_right: float,
        ry_top: float, ry_bottom: float,
        offx_px: float, offy_px: float,
        base_w: int, base_h: int
    ):
        """ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§è¨ˆç®—ã•ã‚ŒãŸå€¤ã‚’ã‚¯ãƒ©ã‚¹å¤‰æ•°ã«ä¿å­˜ã™ã‚‹"""
        self.rx_left = rx_left
        self.rx_right = rx_right
        self.ry_top = ry_top
        self.ry_bottom = ry_bottom
        self.offx_px = offx_px
        self.offy_px = offy_px
        self.base_w = base_w
        self.base_h = base_h
        self.calibrated = True

    def estimate(self, frame_bgr: np.ndarray):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‹ã‚‰é¡”ã‚’æ¤œå‡ºã—ã€è¦–ç·šï¼ˆç›®ã®ä¸­å¿ƒã€è¦–ç·šã®å…ˆï¼‰ã‚’æ¨å®šã™ã‚‹"""
        h, w, _ = frame_bgr.shape
        rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        res = self.face_mesh.process(rgb)

        if not res.multi_face_landmarks:
            return False, None, None, None

        lm = res.multi_face_landmarks[0].landmark

        lc = self._center(lm, self.LEFT_EYE)
        rc = self._center(lm, self.RIGHT_EYE)
        if lc is None or rc is None:
            return False, None, None, None
        eye_center = (lc + rc) / 2.0
        eye_px = (int(eye_center[0] * w), int(eye_center[1] * h))

        li_px = self._iris_center_circle_px(lm, self.LEFT_IRIS, w, h)
        ri_px = self._iris_center_circle_px(lm, self.RIGHT_IRIS, w, h)
        if li_px is None or ri_px is None:
            return False, None, None, None
        iris_px = ((li_px[0] + ri_px[0]) * 0.5, (li_px[1] + ri_px[1]) * 0.5)

        iris_center = np.array([iris_px[0] / w, iris_px[1] / h])
        eye_center_n = np.array([eye_center[0], eye_center[1]])
        raw_vec = iris_center - eye_center_n

        if self.calibrated and self.rx_left is not None and self.rx_right is not None \
           and self.ry_top is not None and self.ry_bottom is not None:
            dx = (self.rx_right - self.rx_left)
            dy = (self.ry_bottom - self.ry_top)

            if abs(dx) < 1e-9 or abs(dy) < 1e-9:
                scale_x = (w - 10) / 0.01
                scale_y = (h - 10) / 0.01
            else:
                scale_x = (w - 10) / dx
                scale_y = (h - 10) / dy

            gx = raw_vec[0] * scale_x + self.offx_px
            gy = raw_vec[1] * scale_y + self.offy_px
        else:
            scale_x = (w - 10) / 0.01
            scale_y = (h - 10) / 0.001
            gx = raw_vec[0] * scale_x
            gy = raw_vec[1] * scale_y

        end_px = (
            int(np.clip(eye_px[0] + gx, 10, w - 10)),
            int(np.clip(eye_px[1] + gy, 10, h - 10)),
        )

        return True, eye_px, end_px, (float(raw_vec[0]), float(raw_vec[1]))


# ================== Region é›†è¨ˆ ==================
class RegionTimer:
    """
    è¦–ç·šãŒå„é ˜åŸŸï¼ˆRegionï¼‰ã«æ»åœ¨ã—ãŸã€Œåˆè¨ˆæ™‚é–“ã€ã¨ã€Œå‹•ä½œé †åºï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼‰ã€ã‚’è¨ˆæ¸¬ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    def __init__(self):
        self.num_regions = 4
        # 1. åˆè¨ˆæ™‚é–“
        self.stats = {1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}
        self.last_ts = None
        # 2. ã‚·ãƒ¼ã‚±ãƒ³ã‚¹è¨˜éŒ²ç”¨
        self.sequence_log: List[Tuple[int, float]] = []
        self.current_region: Optional[int] = None
        self.current_region_start_time: Optional[float] = None

    def region_of(self, x: int, y: int, w: int, h: int) -> Optional[int]:
        """æŒ‡å®šã•ã‚ŒãŸåº§æ¨™(x, y)ãŒã€å®šç¾©æ¸ˆã¿ã®4é ˜åŸŸã®ã©ã‚Œã«å±ã™ã‚‹ã‹ã‚’è¿”ã™"""
        if (0.20 * w < x < 0.70 * w) and (0.05 * h < y < 0.15 * h): return 1
        if (x > 0.73 * w) and (0.05 * h < y < 0.60 * h): return 4
        if (x < 0.22 * w) and (y > 0.60 * h): return 3
        if (0.22 * w < x < 0.73 * w) and (0.15 * h < y < 0.90 * h): return 2
        return None

    def update(self, gaze_px: Tuple[int, int], w: int, h: int):
        """è¦–ç·šåº§æ¨™(gaze_px)ã‚’å—ã‘å–ã‚Šã€åˆè¨ˆæ™‚é–“ã¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’æ›´æ–°ã™ã‚‹"""
        now = time.time()
        if self.last_ts is None:
            self.last_ts = now
            self.current_region = self.region_of(gaze_px[0], gaze_px[1], w, h)
            if self.current_region is not None:
                self.current_region_start_time = now
            return

        dt = now - self.last_ts
        self.last_ts = now
        r = self.region_of(gaze_px[0], gaze_px[1], w, h)

        if r is not None and r in self.stats:
            self.stats[r] += dt

        if r != self.current_region:
            if self.current_region is not None and self.current_region_start_time is not None:
                duration = now - self.current_region_start_time
                self.sequence_log.append((self.current_region, duration))
            self.current_region = r
            self.current_region_start_time = now if r is not None else None

    def stop(self):
        """ åˆ†æçµ‚äº†æ™‚ã«å‘¼ã³å‡ºã—ã€æœ€å¾Œã®ãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹ """
        now = time.time()
        if self.current_region is not None and self.current_region_start_time is not None:
            duration = now - self.current_region_start_time
            self.sequence_log.append((self.current_region, duration))
        self.current_region = None
        self.current_region_start_time = None


def y_intercept(rx_left, rx_right, w):
    """ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ç·šå½¢å¤‰æ›ã®ä¿‚æ•°ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«a, ã‚ªãƒ•ã‚»ãƒƒãƒˆbï¼‰ã‚’è¨ˆç®—ã™ã‚‹"""
    if abs(rx_right - rx_left) < 1e-9: return 0, 0
    a = w / (rx_right - rx_left)
    b = -(w/2) * (rx_right + rx_left) / (rx_right - rx_left)
    return a, b

# ================== ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆã‚¯ãƒ©ã‚¹ ==================
class HeatmapGenerator:
    """è¦–ç·šãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆãƒ»ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    # (å¤‰æ›´ãªã—)
    def __init__(self, width: int, height: int):
        self.width = width; self.height = height
        self.heatmap_data = np.zeros((height, width), dtype=np.float64)
        self.decay_rate = 0.98; self.intensity = 5.0
        self.radius = int(max(width, height) * 0.15)
    def update(self, gaze_point: Tuple[int, int]):
        x, y = gaze_point
        if x is None or y is None: return
        x_grid, y_grid = np.ogrid[:self.height, :self.width]
        dist_sq = (x_grid - y)**2 + (y_grid - x)**2
        gauss = self.intensity * np.exp(-dist_sq / (2 * (self.radius / 2)**2))
        self.heatmap_data += gauss
    def decay(self):
        self.heatmap_data *= self.decay_rate
        self.heatmap_data[self.heatmap_data < 0.01] = 0
    def generate_minimap_image(self, current_gaze_point: Optional[Tuple[int, int]]) -> np.ndarray:
        minimap_bg = np.zeros((self.height, self.width, 3), dtype=np.uint8)
        cv2.rectangle(minimap_bg, (0, 0), (self.width, self.height), (30, 30, 30), -1)
        if np.max(self.heatmap_data) > 0:
            norm_heatmap = self.heatmap_data / np.max(self.heatmap_data)
            heatmap_8u = (norm_heatmap * 255).astype(np.uint8)
            heatmap_color = cv2.applyColorMap(heatmap_8u, cv2.COLORMAP_JET)
            minimap_bg = cv2.addWeighted(minimap_bg, 0.5, heatmap_color, 0.5, 0)
        if current_gaze_point:
            cv2.circle(minimap_bg, current_gaze_point, 5, (0, 0, 255), -1)
            cv2.circle(minimap_bg, current_gaze_point, 7, (255, 255, 255), 1)
        cv2.rectangle(minimap_bg, (0, 0), (self.width - 1, self.height - 1), (255, 255, 255), 1)
        return minimap_bg

# ================ Video Processor =================
class VideoProcessor:
    """Webã‚«ãƒ¡ãƒ©ã®å„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã™ã‚‹æœ¬ä½“"""
    # (å¤‰æ›´ãªã—)
    def __init__(self):
        self.est = GazeEstimator(0.5, 0.5); self.running = False
        self.targets = [("å·¦ä¸Š", 0.10, 0.10), ("å³ä¸Š", 0.90, 0.10), ("å·¦ä¸‹", 0.10, 0.90), ("å³ä¸‹", 0.90, 0.90)]
        self.calibrating = False; self.target_idx = 0; self.capture_request = False
        self.capture_buffer: List[Tuple[float, float, int, int]] = []
        self.samples: Dict[str, Tuple[float, float, float, float]] = {}
        self.last_w: Optional[int] = None; self.last_h: Optional[int] = None; self.calib_ready = False
        self.fps_start_time = 0; self.fps_frame_count = 0; self.fps = 0.0
        self.minimap_width = 220; self.minimap_height = 140
        self.heatmap_generator = HeatmapGenerator(self.minimap_width, self.minimap_height)
        self.show_heatmap = True; self.num_regions = 4; self.timer = RegionTimer()
    def start_calibration(self):
        self.calibrating = True; self.calib_ready = False; self.target_idx = 0
        self.capture_request = False; self.capture_buffer.clear(); self.samples.clear()
    def request_sample(self):
        if self.calibrating and self.target_idx < len(self.targets):
            self.capture_request = True; self.capture_buffer.clear()
    def skip_target(self):
        if self.calibrating and self.target_idx < len(self.targets):
            self.target_idx += 1; self.capture_request = False; self.capture_buffer.clear()
            if self.target_idx >= len(self.targets): self.calib_ready = True
    def reset_calibration(self): self.start_calibration()
    def _compute_and_apply_calibration(self) -> Tuple[bool, str]:
        need = {"å·¦ä¸Š", "å³ä¸Š", "å·¦ä¸‹", "å³ä¸‹"}
        if not need.issubset(self.samples.keys()): return False, "å››éš…ã®ã‚µãƒ³ãƒ—ãƒ«ãŒæƒã£ã¦ã„ã¾ã›ã‚“ã€‚"
        if self.last_w is None or self.last_h is None: return False, "ã‚«ãƒ¡ãƒ©ã‹ã‚‰æ˜ åƒãŒå–å¾—ã§ãã¦ã„ã¾ã›ã‚“ã€‚"
        rx_lu, ry_lu, ex_lu, ey_lu = self.samples["å·¦ä¸Š"]; rx_ru, ry_ru, ex_ru, ey_ru = self.samples["å³ä¸Š"]
        rx_ld, ry_ld, ex_ld, ey_ld = self.samples["å·¦ä¸‹"]; rx_rd, ry_rd, ex_rd, ey_rd = self.samples["å³ä¸‹"]
        rx_left = (rx_lu + rx_ld) / 2.0; rx_right = (rx_ru + rx_rd) / 2.0
        ry_top = (ry_lu + ry_ru) / 2.0; ry_bottom = (ry_ld + ry_rd) / 2.0
        w, h = self.last_w, self.last_h; dx = rx_right - rx_left; dy = ry_bottom - ry_top
        if abs(dx) < 1e-9 or abs(dy) < 1e-9: return False, "å·®åˆ†ãŒå°ã•ã™ãã¾ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ã‚’å–ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚"
        scale_x, offx = y_intercept(rx_left, rx_right, w); scale_y, offy = y_intercept(ry_top, ry_bottom, h)
        self.est.set_calibration_values(
            rx_left=rx_left, rx_right=rx_right, ry_top=ry_top, ry_bottom=ry_bottom,
            offx_px=float(offx), offy_px=float(offy), base_w=w, base_h=h)
        return True, (f"é©ç”¨ OK: dx={dx:.6g}, dy={dy:.6g}, offx={offx:.1f}px, offy={offy:.1f}px, "
                      f"scale_x={scale_x:.1f}, scale_y={scale_y:.1f} @ {w}x{h}, samples={rx_left, rx_right, ry_top, ry_bottom}")
    def _draw_guides(self, frame):
        h, w, _ = frame.shape; color = (0, 255, 0); thickness = 2
        r1_x1, r1_y1 = int(0.20 * w), int(0.05 * h); r1_x2, r1_y2 = int(0.70 * w), int(0.15 * h)
        cv2.rectangle(frame, (r1_x1, r1_y1), (r1_x2, r1_y2), color, thickness)
        cv2.putText(frame, "I", (r1_x1 + 5, r1_y1 + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
        r2_x1, r2_y1 = int(0.22 * w), int(0.15 * h); r2_x2, r2_y2 = int(0.73 * w), int(0.90 * h)
        cv2.rectangle(frame, (r2_x1, r2_y1), (r2_x2, r2_y2), color, thickness)
        cv2.putText(frame, "II", (r2_x1 + 5, r2_y1 + 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)
        r3_x1, r3_y1 = int(0), int(0.60 * h); r3_x2, r3_y2 = int(0.22 * w), int(h)
        cv2.rectangle(frame, (r3_x1, r3_y1), (r3_x2, r3_y2), color, thickness)
        cv2.putText(frame, "III", (r3_x1 + 5, r3_y1 + 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)
        r4_x1, r4_y1 = int(0.73 * w), int(0.05 * h); r4_x2, r4_y2 = int(w), int(0.60 * h)
        cv2.rectangle(frame, (r4_x1, r4_y1), (r4_x2, r4_y2), color, thickness)
        cv2.putText(frame, "IV", (r4_x1 + 5, r4_y1 + 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)
    def _draw_calib_target(self, frame):
        if not self.calibrating: return; h, w, _ = frame.shape
        if self.calib_ready or self.target_idx >= len(self.targets): return
        name, nx, ny = self.targets[self.target_idx]; px, py = int(nx * w), int(ny * h)
        cv2.circle(frame, (px, py), 16, (0, 255, 0), 3); cv2.circle(frame, (px, py), 6, (0, 255, 255), -1)
    def draw_overlay(self, frame: np.ndarray, eye_px, end_px):
        if eye_px and end_px:
            cv2.circle(frame, eye_px, 6, (255, 255, 255), -1); cv2.circle(frame, end_px, 6, (0, 255, 255), -1)
            for i in range(8):
                t = i / (8 - 1); x = int(eye_px[0] + t * (end_px[0] - eye_px[0])); y = int(eye_px[1] + t * (end_px[1] - eye_px[1]))
                cv2.circle(frame, (x, y), max(2, 6 - i), (0, 200, 255), -1)
        return frame
    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24"); img = cv2.flip(img, 1); h, w, _ = img.shape
        self.last_w, self.last_h = img.shape[1], img.shape[0]
        ok, eye_px, end_px, raw_vec = self.est.estimate(img)
        if self.fps_start_time == 0: self.fps_start_time = time.time()
        self.fps_frame_count += 1; elapsed_time = time.time() - self.fps_start_time
        if elapsed_time >= 1.0:
            self.fps = self.fps_frame_count / elapsed_time; self.fps_frame_count = 0; self.fps_start_time = time.time()
        if self.calibrating and self.capture_request and ok and raw_vec:
            self.capture_buffer.append((raw_vec[0], raw_vec[1], eye_px[0], eye_px[1]))
            if len(self.capture_buffer) >= 15:
                avg = np.mean(self.capture_buffer, axis=0); name, _, _ = self.targets[self.target_idx]
                self.samples[name] = tuple(float(v) for v in avg)
                self.capture_request = False; self.capture_buffer.clear(); self.target_idx += 1
                if self.target_idx >= len(self.targets): self.calib_ready = True
        current_minimap_gaze = None
        if self.running and ok and end_px:
            self.timer.update(end_px, w, h)
            if self.show_heatmap:
                minimap_x = int((end_px[0] / w) * self.minimap_width); minimap_y = int((end_px[1] / h) * self.minimap_height)
                current_minimap_gaze = (minimap_x, minimap_y)
                self.heatmap_generator.update(current_minimap_gaze)
        if self.show_heatmap:
            self.heatmap_generator.decay(); minimap_image = self.heatmap_generator.generate_minimap_image(current_minimap_gaze)
            margin = 10; map_h, map_w, _ = minimap_image.shape; y_offset = h - map_h - margin; x_offset = w - map_w - margin
            img[y_offset:y_offset + map_h, x_offset:x_offset + map_w] = minimap_image
        img = self.draw_overlay(img, eye_px if ok else None, end_px if ok else None); self._draw_guides(img)
        if self.calibrating and not self.calib_ready and self.target_idx < len(self.targets):
            name, nx, ny = self.targets[self.target_idx]; px, py = int(nx * w), int(ny * h)
            cv2.circle(img, (px, py), 16, (0, 255, 0), 3); cv2.circle(img, (px, py), 6, (0, 255, 255), -1)
        fps_text = f"FPS: {self.fps:.1f}"; cv2.putText(img, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        return av.VideoFrame.from_ndarray(img, format="bgr24")
    def apply_calibration(self) -> Tuple[bool, str]:
        return self._compute_and_apply_calibration()

def get_region_labels(num_regions: int) -> Dict[int, str]:
    """é ˜åŸŸIDã«å¯¾å¿œã™ã‚‹ãƒ©ãƒ™ãƒ«(I, II, III, IV)ã‚’è¿”ã™"""
    if num_regions == 4:
        return {1: "I: ã‚¨ãƒ©ãƒ¼æ–‡å­—", 2: "II: åŸºç›¤ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦", 3: "III: 3Dãƒ‡ãƒ¼ã‚¿ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦", 4: "IV: éå»ã®NGä¾‹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦"}
    if num_regions == 3: # éå»ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ç”¨
        return {1: "â‘  å·¦", 2: "â‘¡ ä¸­å¤®", 3: "â‘¢ å³"}
    return {i: f"ã‚¨ãƒªã‚¢ {i}" for i in range(1, num_regions + 1)}


# ================= åˆ†æãƒ¬ãƒãƒ¼ãƒˆ (åˆè¨ˆæ™‚é–“æ¯”è¼ƒ) =================
def generate_analysis_report(
    actual_stats: Dict[int, float],
    standard_durations: Dict[int, float],
    labels: Dict[int, str]
) -> Tuple[str, str]:
    """
    æ¨™æº–å‹•ä½œï¼ˆåˆè¨ˆæ™‚é–“ï¼‰ã¨åˆ†æå‹•ä½œï¼ˆåˆè¨ˆæ™‚é–“ï¼‰ã‚’æ¯”è¼ƒã—ã€
    "æ¨™æº–å‹•ä½œï¼š..." ã¨ "åˆ†æå‹•ä½œï¼š..." ã®2ã¤ã®æ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    standard_parts = []
    analysis_parts = []

    for region_id in sorted(standard_durations.keys()):
        label_name = labels.get(region_id, f"Region {region_id}").split(":")[0]
        standard_sec = standard_durations.get(region_id, 0.0)
        actual_sec = actual_stats.get(region_id, 0.0)

        standard_parts.append(f"{label_name}({standard_sec:.0f}ç§’)")

        symbol, comment = compute_analysis_comment(actual_sec, standard_sec)

        analysis_parts.append(f"{label_name}({actual_sec:.1f}ç§’: {symbol} {comment})")

    standard_str = "â†’".join(standard_parts)
    analysis_str = "â†’".join(analysis_parts)

    return standard_str, analysis_str


def compute_analysis_comment(actual_sec: float, standard_sec: float, tolerance: float = 1.0) -> Tuple[str, str]:
    """
    actual_sec ã¨ standard_sec ã‚’æ¯”è¼ƒã—ã¦ã€(symbol, comment) ã‚’è¿”ã™å…±é€šãƒ­ã‚¸ãƒƒã‚¯ã€‚
    symbol: â—¯/â–³/Ã—ã€comment: æ—¥æœ¬èªã®èª¬æ˜
    """
    if actual_sec == 0:
        return "Ã—", "è¦‹ã¦ã„ãªã„å¯èƒ½æ€§ãŒé«˜ã„ã§ã™"
    elif actual_sec > standard_sec:
        return "â—¯", "æ¨™æº–å‹•ä½œé€šã‚Šã«è¦‹ã¦ã„ã¾ã™"
    elif actual_sec < standard_sec:
        return "â–³", "è¦‹ã¦ã„ã‚‹æ™‚é–“ãŒçŸ­ã„ã§ã™"


def generate_analysis_parts(
    actual_stats: Dict[int, float],
    standard_durations: Dict[int, float],
    labels: Dict[int, str]
) -> Tuple[List[str], List[str]]:
    """
    æ¨™æº–å‹•ä½œã¨åˆ†æå‹•ä½œã‚’ã€ãã‚Œãã‚Œè¡Œã”ã¨ã®ãƒªã‚¹ãƒˆã§è¿”ã™ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€‚
    UIã§ "ä¸€è¡Œãšã¤è¡¨ç¤º" ã—ãŸã„ã¨ãã«ä½¿ã„ã¾ã™ã€‚
    """
    standard_parts: List[str] = []
    analysis_parts: List[str] = []

    for region_id in sorted(standard_durations.keys()):
        label_name = labels.get(region_id, f"Region {region_id}").split(":")[0]
        standard_sec = standard_durations.get(region_id, 0.0)
        actual_sec = actual_stats.get(region_id, 0.0)

        standard_parts.append(f"{label_name}({standard_sec:.0f}ç§’)")

        symbol, comment = compute_analysis_comment(actual_sec, standard_sec)

        analysis_parts.append(f"{label_name}({actual_sec:.1f}ç§’): {symbol} {comment}")

    return standard_parts, analysis_parts


def generate_analysis_map(
    actual_stats: Dict[int, float],
    standard_durations: Dict[int, float],
    labels: Dict[int, str]
) -> Dict[int, str]:
    """
    å„é ˜åŸŸã”ã¨ã®ç°¡æ˜“åˆ†ææ–‡å­—åˆ—ã‚’è¿”ã™ãƒãƒƒãƒ— {region_id: "â—¯ æ¨™æº–å‹•ä½œé€šã‚Šã«è¦‹ã¦ã„ã¾ã™"}
    UIã®è¡¨ã«æŒ¿å…¥ã™ã‚‹ãŸã‚ã«ä½¿ã„ã¾ã™ã€‚
    """
    result: Dict[int, str] = {}
    tolerance = 1.0
    for region_id in sorted(standard_durations.keys()):
        standard_sec = standard_durations.get(region_id, 0.0)
        actual_sec = actual_stats.get(region_id, 0.0)

        symbol, comment = compute_analysis_comment(actual_sec, standard_sec)

        result[region_id] = f"{symbol} {comment}"

    return result

# ================= ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ–‡å­—åˆ— =================
def generate_sequence_string(
    sequence_log: List[Tuple[int, float]],
    labels: Dict[int, str]
) -> str:
    """
    ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ­ã‚°ã‚’ 'I(1.2s) -> III(0.8s) -> ...' å½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹
    """
    if not sequence_log:
        return "ï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰"

    MIN_DISPLAY_SEC = 0.05

    filtered: List[Tuple[int, float]] = [ (rid, d) for (rid, d) in sequence_log if d >= MIN_DISPLAY_SEC ]
    if not filtered:
        return "ï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰"

    parts = []
    for region_id, duration_sec in filtered:
        label_name = labels.get(region_id, f"Region {region_id}").split(":")[0]
        parts.append(f"{label_name}({duration_sec:.1f}s)")

    return " â†’ ".join(parts)


def generate_sequence_list(
    sequence_log: List[Tuple[int, float]],
    labels: Dict[int, str]
) -> List[str]:
    """
    ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ­ã‚°ã‚’å€‹åˆ¥è¡Œã®ãƒªã‚¹ãƒˆã§è¿”ã™ã€‚UIã§ç®‡æ¡æ›¸ãè¡¨ç¤ºã™ã‚‹ã¨ãã«ä½¿ã†ã€‚
    """
    if not sequence_log:
        return []

    MIN_DISPLAY_SEC = 0.05
    filtered = [(rid, d) for (rid, d) in sequence_log if d >= MIN_DISPLAY_SEC]
    if not filtered:
        return []

    parts: List[str] = []
    for region_id, duration_sec in filtered:
        label_name = labels.get(region_id, f"Region {region_id}").split(":")[0]
        parts.append(f"{label_name}({duration_sec:.1f}s)")

    return parts


# ================= PDF (â˜…â˜… ä¿®æ­£ â˜…â˜…) =================
JAPANESE_FONT_PATH = "ipaexg00401/ipaexg.ttf"
STANDARD_DURATIONS = {1: 2.0, 2: 4.0, 3: 3.0, 4: 3.0}

def create_history_pdf(history_data: list) -> io.BytesIO:
    """
    å±¥æ­´ãƒ‡ãƒ¼ã‚¿(history_data)ã‚’å—ã‘å–ã‚Šã€PDFãƒ•ã‚¡ã‚¤ãƒ«(BytesIO)ã‚’ç”Ÿæˆã™ã‚‹
    """
    pdf = FPDF()
    pdf.add_page()
    pdf.add_font('Japanese', '', JAPANESE_FONT_PATH, uni=True)
    pdf.set_font('Japanese', '', 16)
    pdf.cell(0, 10, "ã‚¢ã‚¤ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°åˆ†æå±¥æ­´", 0, 1, 'C')
    pdf.ln(5)

    # PDFã®å…ˆé ­ã«ã€ŒåŸºæº–ï¼ˆæ¨™æº–å‹•ä½œï¼‰ã€ã‚’è¨˜è¼‰
    standard_labels_for_pdf = get_region_labels(4)
    standard_str, _ = generate_analysis_report({}, STANDARD_DURATIONS, standard_labels_for_pdf)
    pdf.set_font('Japanese', '', 12)
    pdf.set_fill_color(245, 245, 245)
    pdf.cell(35, 8, "åŸºæº– (æ¨™æº–å‹•ä½œ):", border=0, fill=False)
    pdf.multi_cell(0, 8, standard_str, border=1, fill=True)
    pdf.ln(5)

    # å±¥æ­´ã‚’1ä»¶ãšã¤å‡¦ç†
    for item in reversed(history_data):
        stats = item.get("stats", {})
        sequence = item.get("sequence", [])
        num_regions = len(stats)
        if num_regions == 0: continue

        labels = get_region_labels(num_regions)

        pdf.set_font('Japanese', '', 12)
        pdf.cell(0, 10, f"è¨˜éŒ²æ—¥æ™‚: {item['time']}", 0, 1)
        pdf.set_font('Japanese', '', 10)
        pdf.set_fill_color(240, 240, 240)

        # --- å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆåˆè¨ˆæ™‚é–“ï¼‰ ---
        cell_width = 60; cell_height = 8
        pdf.cell(cell_width, cell_height, "ç¯„å›² (åˆè¨ˆ)", border=1, fill=True, align='C')

        is_4_region_history = (num_regions == 4)
        if is_4_region_history:
            pdf.set_font('Japanese', '', 9)
            pdf.cell(cell_width, cell_height, "æ¨™æº–å‹•ä½œ (ç§’)", border=1, fill=True, align='C')
            pdf.cell(cell_width, cell_height, "åˆè¨ˆç§’", border=1, fill=True, align='C')
            pdf.set_font('Japanese', '', 10)
        else:
             pdf.cell(cell_width, cell_height, "åˆè¨ˆç§’", border=1, fill=True, align='C')
        pdf.ln()

        for i in sorted(stats.keys()):
            pdf.cell(cell_width, cell_height, labels.get(i, f"Region {i}"), border=1)
            if is_4_region_history:
                standard_sec = STANDARD_DURATIONS.get(i, 0.0)
                pdf.cell(cell_width, cell_height, f"{standard_sec:.1f}", border=1, align='C')
            pdf.cell(cell_width, cell_height, f"{stats.get(i, 0.0):.1f}", border=1, align='C')
            pdf.ln()

        # --- åˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆåˆè¨ˆæ™‚é–“ â—¯â–³Ã—ï¼‰ ---
        if num_regions == 4:
            _, analysis_str = generate_analysis_report(stats, STANDARD_DURATIONS, labels)
            pdf.set_font('Japanese', '', 10)
            # æ˜ç¤ºçš„ã«å·¦ç«¯ã«æˆ»ã—ã¦å·¦å¯„ã›ã§å‡ºåŠ›ã™ã‚‹
            pdf.set_x(pdf.l_margin)
            pdf.cell(0, 8, "åˆ†æå‹•ä½œ(åˆè¨ˆ):", border=0, ln=1, align='L')
            pdf.set_fill_color(250, 250, 250)
            # multi_cell ã‚’ãƒšãƒ¼ã‚¸ã®å·¦ç«¯ã‹ã‚‰é–‹å§‹ (width=0)
            pdf.multi_cell(0, 8, analysis_str, border=1, fill=True, align='L')

        # --- å®Ÿéš›ã®é †åº ---
        if sequence:
            sequence_str = generate_sequence_string(sequence, labels)
            pdf.set_font('Japanese', '', 10)
            # â˜…â˜… (ä¿®æ­£) ãƒ©ãƒ™ãƒ«ã‚»ãƒ«ã« ln=1 ã‚’è¿½åŠ ã—ã¦æ”¹è¡Œ â˜…â˜…
            # æ˜ç¤ºçš„ã«å·¦ç«¯ã«æˆ»ã—ã¦å·¦å¯„ã›ã§å‡ºåŠ›ã™ã‚‹
            pdf.set_x(pdf.l_margin)
            pdf.cell(0, 8, "å®Ÿéš›ã®é †åº:", border=0, ln=1, align='L')
            pdf.set_fill_color(250, 250, 250)
            # â˜…â˜… (ä¿®æ­£) multi_cell ã‚’ãƒšãƒ¼ã‚¸ã®å·¦ç«¯ã‹ã‚‰é–‹å§‹ (width=0) â˜…â˜…
            pdf.multi_cell(0, 8, sequence_str, border=1, fill=True, align='L')

        pdf.ln(10)

    return io.BytesIO(pdf.output())


# ================= Streamlit UI (â˜…â˜… ä¿®æ­£ â˜…â˜…) ==================
st.set_page_config(page_title="åŸºæ¿å®Ÿè£…çŠ¶æ…‹ã®ç¢ºèªä½œæ¥­ ã‚¢ã‚¤ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("åŸºæ¿å®Ÿè£…çŠ¶æ…‹ã®ç¢ºèªä½œæ¥­ ã‚¢ã‚¤ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– ---
if "history" not in st.session_state: st.session_state.history = []
if "running" not in st.session_state: st.session_state.running = False
st.session_state.num_regions = 4
if "current_stats" not in st.session_state or len(st.session_state.current_stats) != 4:
    st.session_state.current_stats = {i: 0.0 for i in range(1, 4 + 1)}
if "current_sequence" not in st.session_state:
    st.session_state.current_sequence = []

region_labels = get_region_labels(4)

# --- ç”»é¢ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ (2ã‚«ãƒ©ãƒ ) ---
cols = st.columns([1, 1])

# --- ã‚«ãƒ©ãƒ 1: ã‚«ãƒ¡ãƒ©ã¨æ“ä½œãƒœã‚¿ãƒ³ ---
with cols[0]:
    st.subheader("ã‚«ãƒ¡ãƒ©æ˜ åƒ")
    show_heatmap_toggle = st.checkbox("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤º", value=True)

    rtc_config = RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]})
    ctx = webrtc_streamer(
        key="eyetracking", mode=WebRtcMode.SENDRECV, video_processor_factory=VideoProcessor,
        async_processing=True, rtc_configuration=rtc_config, media_stream_constraints={"video": True, "audio": False})

    if ctx.state.playing and ctx.video_processor:
        ctx.video_processor.show_heatmap = show_heatmap_toggle
        ctx.video_processor.num_regions = 4

    c1, c2, c3 = st.columns(3)
    with c1:
        if st.button("åˆ†æé–‹å§‹", use_container_width=True):
            if ctx.state.playing:
                st.session_state.running = True
                if ctx.video_processor:
                    ctx.video_processor.num_regions = 4
                    ctx.video_processor.running = True
                    ctx.video_processor.timer = RegionTimer()
                    st.session_state.current_stats = ctx.video_processor.timer.stats.copy()
                    st.session_state.current_sequence = ctx.video_processor.timer.sequence_log.copy()
            else: st.warning("ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã¦ä¸‹ã•ã„")
    with c2:
        if st.button("åˆ†æçµ‚äº†", use_container_width=True):
            if ctx.state.playing and st.session_state.running:
                st.session_state.running = False
                if ctx.video_processor:
                    ctx.video_processor.running = False
                    ctx.video_processor.timer.stop()
                    stats = ctx.video_processor.timer.stats
                    sequence = ctx.video_processor.timer.sequence_log
                    st.session_state.current_stats = stats
                    st.session_state.current_sequence = sequence
                    st.session_state.history.append({
                        "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "stats": stats.copy(),
                        "sequence": sequence.copy()
                    })
            else: st.warning("åˆ†æãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    with c3:
        if st.button("ã‚­ãƒ£ãƒªãƒ–é–‹å§‹", use_container_width=True):
            if ctx.state.playing:
                ctx.video_processor.start_calibration()
                st.success("ã‚­ãƒ£ãƒªãƒ–ã‚’é–‹å§‹ã€‚å„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’è¦‹ã¦ã€ã‚µãƒ³ãƒ—ãƒ«å–å¾—ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            else: st.warning("ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã¦ä¸‹ã•ã„")

    if ctx.state.playing and ctx.video_processor and ctx.video_processor.calibrating:
        d1, d2, d3 = st.columns(3)
        with d1:
            if st.button("ã‚µãƒ³ãƒ—ãƒ«å–å¾—ï¼ˆ15fï¼‰", use_container_width=True):
                if not ctx or not ctx.state.playing: st.warning("ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã¦ä¸‹ã•ã„")
                elif not ctx.video_processor or not ctx.video_processor.calibrating: st.warning("ã¾ãšã€ã‚­ãƒ£ãƒªãƒ–é–‹å§‹ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„")
                else:
                    ctx.video_processor.request_sample(); st.info("å–å¾—ä¸­â€¦ï¼ˆ15ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰")
        with d2:
            if st.button("ãƒªã‚»ãƒƒãƒˆ"): ctx.video_processor.reset_calibration()
        with d3:
            if st.button("é©ç”¨"):
                ok, msg = ctx.video_processor.apply_calibration()
                if ok:
                    st.success(msg)
                else:
                    st.error(msg)

        order = [t[0] for t in ctx.video_processor.targets]
        marks = ["âœ…" if name in ctx.video_processor.samples else "â¬œ" for name in order]
        st.caption("å–å¾—çŠ¶æ³: " + " | ".join(f"{m} {n}" for m, n in zip(marks, order)))
        if ctx.video_processor.calib_ready: st.success("å››éš…ã®ã‚µãƒ³ãƒ—ãƒ«ãŒæƒã„ã¾ã—ãŸã€‚ã€é©ç”¨ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        elif ctx.video_processor.target_idx < len(order): st.caption(f"æ¬¡ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {order[ctx.video_processor.target_idx]}")

    if ctx.state.playing and ctx.video_processor and st.session_state.running:
        st.session_state.current_stats = ctx.video_processor.timer.stats
        st.session_state.current_sequence = ctx.video_processor.timer.sequence_log

# --- ã‚«ãƒ©ãƒ 2: åˆ†æçµæœ ---
with cols[1]:
    st.subheader("ä»Šå›ã®åˆ†æçµæœ (åˆè¨ˆæ™‚é–“)")
    cur_stats = st.session_state.current_stats

    # --- åˆ†æçµæœãƒ†ãƒ¼ãƒ–ãƒ« (4åˆ—: ç¯„å›² / æ¨™æº– / åˆè¨ˆ / åˆ†æçµæœ) ---
    analysis_map = generate_analysis_map(cur_stats, STANDARD_DURATIONS, region_labels)

    table_data = {
        "ç¯„å›²": [],
        "æ¨™æº–å‹•ä½œ (ç§’)": [],
        "åˆè¨ˆç§’": [],
        "åˆ†æçµæœ": []
    }

    for region_id in sorted(STANDARD_DURATIONS.keys()):
        label = region_labels.get(region_id, f"ã‚¨ãƒªã‚¢ {region_id}")
        standard_sec = STANDARD_DURATIONS.get(region_id, 0.0)
        actual_sec = cur_stats.get(region_id, 0.0)
        table_data["ç¯„å›²"].append(label)
        table_data["æ¨™æº–å‹•ä½œ (ç§’)"].append(f"{standard_sec:.1f}")
        table_data["åˆè¨ˆç§’"].append(f"{actual_sec:.1f}")
        table_data["åˆ†æçµæœ"].append(analysis_map.get(region_id, ""))

    st.table(table_data)

    # --- å®Ÿéš›ã®å‹•ä½œé †åº ---
    st.markdown("---")
    st.subheader("å®Ÿéš›ã®å‹•ä½œé †åº")
    cur_sequence = st.session_state.current_sequence
    sequence_str = generate_sequence_string(cur_sequence, region_labels)
    st.text(sequence_str)

    st.markdown("---")

    # --- JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ ---
    # JSON ç”¨ã«ã¯å¾“æ¥ã®çµåˆæ–‡å­—åˆ—ã‚‚ç”Ÿæˆã—ã¦ãŠã
    standard_str, analysis_str = generate_analysis_report(cur_stats, STANDARD_DURATIONS, region_labels)

    json_str = json.dumps({
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_stats": {
            region_labels.get(i, f"Region {i}"): {"duration_sec": f"{cur_stats.get(i, 0.0):.1f}"}
            for i in range(1, 4 + 1)
        },
        "analysis_report_total": {
            "standard": standard_str,
            "actual": analysis_str
        },
        "sequence_log": [
            {"region_id": r_id, "label": region_labels.get(r_id, ""), "duration_sec": f"{dur:.2f}"}
            for r_id, dur in cur_sequence
        ],
        "sequence_string": generate_sequence_string(cur_sequence, region_labels)
    }, ensure_ascii=False, indent=2)
    st.download_button(
        label="çµæœã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=json_str,
        file_name=f"gaze_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json",
    )

# --- å±¥æ­´ã‚»ã‚¯ã‚·ãƒ§ãƒ³ (ã‚«ãƒ©ãƒ ã®å¤–) ---
st.markdown("---")
st.subheader("å±¥æ­´")

if not st.session_state.history:
    st.info("ã¾ã å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã€åˆ†æé–‹å§‹ã€â†’ã€åˆ†æçµ‚äº†ã€ã§è¿½åŠ ã•ã‚Œã¾ã™ã€‚")
else:
    # --- PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ ---
    if not os.path.exists(JAPANESE_FONT_PATH):
        st.error(f"æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {JAPANESE_FONT_PATH}\n"
                 "PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
    else:
        pdf_data = create_history_pdf(st.session_state.history) # ä¿®æ­£æ¸ˆã¿ã®PDFé–¢æ•°
        st.download_button(
            label="ğŸ“ˆ å…¨ã¦ã®å±¥æ­´ã‚’PDFã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=pdf_data,
            file_name=f"gaze_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
            mime="application/pdf",
        )

    # --- å±¥æ­´ã‚’ä¸€ä»¶ãšã¤è¡¨ç¤º ---
    for item in reversed(st.session_state.history):
        with st.expander(f"{item['time']} ã®çµæœ"):
            stats = item.get("stats", {})
            sequence = item.get("sequence", [])
            num_regions_in_history = len(stats)
            if num_regions_in_history == 0: continue

            history_labels = get_region_labels(num_regions_in_history)

            # --- åˆ†æçµæœãƒ†ãƒ¼ãƒ–ãƒ« (ç¯„å›² / æ¨™æº– / åˆè¨ˆ / åˆ†æçµæœ) ---
            history_analysis_map = generate_analysis_map(stats, STANDARD_DURATIONS, history_labels)

            history_table_data = {
                "ç¯„å›²": [],
                "æ¨™æº–å‹•ä½œ (ç§’)": [],
                "åˆè¨ˆç§’": [],
                "åˆ†æçµæœ": []
            }

            for i in sorted(stats.keys()):
                label = history_labels.get(i, f"ã‚¨ãƒªã‚¢ {i}")
                actual_sec = stats.get(i, 0.0)
                history_table_data["ç¯„å›²"].append(label)
                # 4é ˜åŸŸå±¥æ­´ã®ã¿æ¨™æº–ç§’ã‚’è¡¨ç¤º
                if num_regions_in_history == 4:
                    history_table_data["æ¨™æº–å‹•ä½œ (ç§’)"].append(f"{STANDARD_DURATIONS.get(i, 0.0):.1f}")
                else:
                    history_table_data["æ¨™æº–å‹•ä½œ (ç§’)"].append("")
                history_table_data["åˆè¨ˆç§’"].append(f"{actual_sec:.1f}")
                history_table_data["åˆ†æçµæœ"].append(history_analysis_map.get(i, ""))

            if num_regions_in_history != 4:
                del history_table_data["æ¨™æº–å‹•ä½œ (ç§’)"]

            st.table(history_table_data)

            # --- å±¥æ­´ãƒ¬ãƒãƒ¼ãƒˆ (åˆè¨ˆæ™‚é–“ â—¯â–³Ã—) ---
            if num_regions_in_history == 4:
                # å±¥æ­´ã‚‚ç®‡æ¡æ›¸ãã§è¡¨ç¤º
                _, analysis_parts = generate_analysis_parts(stats, STANDARD_DURATIONS, history_labels)
                st.text("åˆ†æå‹•ä½œ(åˆè¨ˆ)ï¼š")
                if analysis_parts:
                    st.markdown("\n".join(f"- {p}" for p in analysis_parts))
                else:
                    st.markdown("ï¼ˆåˆ†æãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")

            # --- å®Ÿéš›ã®é †åº ---
            if sequence:
                sequence_str = generate_sequence_string(sequence, history_labels)
                st.text("å®Ÿéš›ã®é †åº:")
                st.text(sequence_str)