import json
import math
import time
from datetime import datetime
from typing import Dict, Tuple, List, Optional

import av
import cv2
import mediapipe as mp
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
from fpdf import FPDF
import os
import io
from PIL import Image, ImageDraw, ImageFont

# ================= è¦–ç·šæ¨å®šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =================

class GazeEstimator:
    """
    MediaPipeã®Face Meshã‚’ä½¿ç”¨ã—ã¦è¦–ç·šã‚’æ¨å®šã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã‚‚å«ã‚€ã€‚
    """

    # MediaPipeã®Face Meshãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    LEFT_EYE = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]
    RIGHT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]
    LEFT_IRIS = [474, 475, 476, 477, 468, 469, 470, 471, 472]
    RIGHT_IRIS = [469, 470, 471, 472, 473, 474, 475, 476, 477]

    def __init__(self, det_conf=0.5, trk_conf=0.5):
        """MediaPipe FaceMeshãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–"""
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,  # è™¹å½©ï¼ˆIRISï¼‰ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã«True
            min_detection_confidence=det_conf,
            min_tracking_confidence=trk_conf,
        )

        # --- ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ‡ãƒ¼ã‚¿ ---
        # è¦–ç·šãƒ™ã‚¯ãƒˆãƒ«(raw_vec)ã®æ°´å¹³ãƒ»å‚ç›´æ–¹å‘ã®æœ€å°ãƒ»æœ€å¤§å€¤
        self.rx_left: Optional[float] = None
        self.rx_right: Optional[float] = None
        self.ry_top: Optional[float] = None
        self.ry_bottom: Optional[float] = None
        # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦è¨ˆç®—ã•ã‚ŒãŸã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆãƒ”ã‚¯ã‚»ãƒ«å˜ä½ï¼‰
        self.offx_px: float = 0.0
        self.offy_px: float = 0.0
        # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¸ˆã¿ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
        self.calibrated: bool = False
        # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚ã®åŸºæº–ã¨ãªã£ãŸç”»é¢ã‚µã‚¤ã‚º
        self.base_w: Optional[int] = None
        self.base_h: Optional[int] = None

    @staticmethod
    def _center(landmarks, idxs):
        """æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ç¾¤ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—ã™ã‚‹"""
        pts = np.array([[landmarks[i].x, landmarks[i].y] for i in idxs if i < len(landmarks)])
        if len(pts) == 0:
            return None
        return pts.mean(axis=0)

    def _iris_center_circle_px(self, landmarks, indices, w, h):
        """
        è™¹å½©ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ç¾¤ã«æœ€å°å¤–æ¥å††ã‚’ã‚ã¦ã¯ã‚ã€ãã®ä¸­å¿ƒåº§æ¨™ï¼ˆãƒ”ã‚¯ã‚»ãƒ«å˜ä½ï¼‰ã‚’è¿”ã™
        """
        pts = [(landmarks[i].x * w, landmarks[i].y * h) for i in indices if i < len(landmarks)]
        if len(pts) < 3:
            return None
        pts_np = np.array(pts, dtype=np.float32)
        (cx, cy), _ = cv2.minEnclosingCircle(pts_np)
        return (cx, cy)

    def set_calibration_values(
        self,
        rx_left: float, rx_right: float,
        ry_top: float, ry_bottom: float,
        offx_px: float, offy_px: float,
        base_w: int, base_h: int
    ):
        """ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§è¨ˆç®—ã•ã‚ŒãŸå€¤ã‚’ã‚¯ãƒ©ã‚¹å¤‰æ•°ã«ä¿å­˜ã™ã‚‹"""
        self.rx_left = rx_left
        self.rx_right = rx_right
        self.ry_top = ry_top
        self.ry_bottom = ry_bottom
        self.offx_px = offx_px
        self.offy_px = offy_px
        self.base_w = base_w
        self.base_h = base_h
        self.calibrated = True

    def estimate(self, frame_bgr: np.ndarray):
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‹ã‚‰é¡”ã‚’æ¤œå‡ºã—ã€è¦–ç·šï¼ˆç›®ã®ä¸­å¿ƒã€è¦–ç·šã®å…ˆï¼‰ã‚’æ¨å®šã™ã‚‹

        æˆ»ã‚Šå€¤:
        - ok (bool): æ¤œå‡ºæˆåŠŸãƒ•ãƒ©ã‚°
        - eye_px (Tuple[int, int]): ç›®ã®ä¸­å¿ƒåº§æ¨™ (ãƒ”ã‚¯ã‚»ãƒ«)
        - end_px (Tuple[int, int]): è¦–ç·šã®å…ˆã®åº§æ¨™ (ãƒ”ã‚¯ã‚»ãƒ«)
        - raw_vec (Tuple[float, float]): ç”Ÿã®è¦–ç·šãƒ™ã‚¯ãƒˆãƒ« (æ­£è¦åŒ–åº§æ¨™ç³»)
        """
        h, w, _ = frame_bgr.shape
        rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        res = self.face_mesh.process(rgb)

        if not res.multi_face_landmarks:
            return False, None, None, None

        lm = res.multi_face_landmarks[0].landmark

        # 1. ç›®ã®ä¸­å¿ƒåº§æ¨™ (å·¦å³ã®å¹³å‡)
        lc = self._center(lm, self.LEFT_EYE)
        rc = self._center(lm, self.RIGHT_EYE)
        if lc is None or rc is None:
            return False, None, None, None
        eye_center = (lc + rc) / 2.0
        eye_px = (int(eye_center[0] * w), int(eye_center[1] * h))

        # 2. è™¹å½©ã®ä¸­å¿ƒåº§æ¨™ (å·¦å³ã®å¹³å‡)
        li_px = self._iris_center_circle_px(lm, self.LEFT_IRIS, w, h)
        ri_px = self._iris_center_circle_px(lm, self.RIGHT_IRIS, w, h)
        if li_px is None or ri_px is None:
            return False, None, None, None
        iris_px = ((li_px[0] + ri_px[0]) * 0.5, (li_px[1] + ri_px[1]) * 0.5)

        # 3. ã€Œç›®ã®ä¸­å¿ƒã€ã‹ã‚‰ã€Œè™¹å½©ã®ä¸­å¿ƒã€ã¸ã®ãƒ™ã‚¯ãƒˆãƒ« (raw_vec) ã‚’è¨ˆç®—
        iris_center = np.array([iris_px[0] / w, iris_px[1] / h]) # è™¹å½©ä¸­å¿ƒã‚’æ­£è¦åŒ–
        eye_center_n = np.array([eye_center[0], eye_center[1]]) # ç›®ã®ä¸­å¿ƒï¼ˆæ­£è¦åŒ–ï¼‰
        raw_vec = iris_center - eye_center_n # (rx, ry)

        # 4. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¸ˆã¿ã‹ã©ã†ã‹ã§å‡¦ç†ã‚’åˆ†å²
        if self.calibrated and self.rx_left is not None and self.rx_right is not None \
           and self.ry_top is not None and self.ry_bottom is not None:
            # --- ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é©ç”¨ ---
            # ç™»éŒ²ã•ã‚ŒãŸraw_vecã®ç¯„å›²ã¨ç¾åœ¨ã®ç”»é¢ã‚µã‚¤ã‚ºã‹ã‚‰ã‚¹ã‚±ãƒ¼ãƒ«ã‚’è¨ˆç®—
            dx = (self.rx_right - self.rx_left)
            dy = (self.ry_bottom - self.ry_top)

            if abs(dx) < 1e-9 or abs(dy) < 1e-9:
                # ã‚¼ãƒ­é™¤ç®—é˜²æ­¢
                scale_x = (w - 10) / 0.01
                scale_y = (h - 10) / 0.01
            else:
                scale_x = (w - 10) / dx
                scale_y = (h - 10) / dy

            # ã‚¹ã‚±ãƒ¼ãƒ«ã¨ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’é©ç”¨
            gx = raw_vec[0] * scale_x + self.offx_px
            gy = raw_vec[1] * scale_y + self.offy_px
        else:
            # --- æœªã‚­ãƒ£ãƒªãƒ–ã®ç°¡æ˜“å‹•ä½œ ---
            # æš«å®šçš„ãªã‚¹ã‚±ãƒ¼ãƒ«ã‚’é©ç”¨ (ã‚ªãƒ•ã‚»ãƒƒãƒˆãªã—)
            scale_x = (w - 10) / 0.01
            scale_y = (h - 10) / 0.001
            gx = raw_vec[0] * scale_x
            gy = raw_vec[1] * scale_y

        # 5. æœ€çµ‚çš„ãªè¦–ç·šåº§æ¨™ (end_px) ã‚’è¨ˆç®—
        end_px = (
            int(np.clip(eye_px[0] + gx, 10, w - 10)), # ç”»é¢å¤–ã«ã¯ã¿å‡ºãªã„ã‚ˆã†ã«clip
            int(np.clip(eye_px[1] + gy, 10, h - 10)),
        )

        return True, eye_px, end_px, (float(raw_vec[0]), float(raw_vec[1]))


# ================== Region é›†è¨ˆ ==================
class RegionTimer:
    """
    è¦–ç·šãŒå„é ˜åŸŸï¼ˆRegionï¼‰ã«æ»åœ¨ã—ãŸåˆè¨ˆæ™‚é–“ã‚’è¨ˆæ¸¬ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    def __init__(self):
        """4é ˜åŸŸåˆ†ã®åˆè¨ˆæ™‚é–“ (stats) ã‚’0ã§åˆæœŸåŒ–"""
        self.num_regions = 4
        # self.stats[1] ãŒ Region I, [2] ãŒ Region II ...
        self.stats = {1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}
        self.last_ts = None # æœ€å¾Œã«updateãŒå‘¼ã°ã‚ŒãŸæ™‚åˆ»

    def region_of(self, x: int, y: int, w: int, h: int) -> Optional[int]:
        """
        æŒ‡å®šã•ã‚ŒãŸåº§æ¨™(x, y)ãŒã€å®šç¾©æ¸ˆã¿ã®4é ˜åŸŸã®ã©ã‚Œã«å±ã™ã‚‹ã‹ã‚’è¿”ã™
        ï¼ˆè¦ä»¶è³‡æ–™ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã«åŸºã¥ãã€ç”»é¢ã‚µã‚¤ã‚º(w, h)ã«å¯¾ã™ã‚‹å‰²åˆã§å®šç¾©ï¼‰
        """
        # Region I: ã‚¨ãƒ©ãƒ¼æ–‡å­— (ä¸Šéƒ¨ä¸­å¤®)
        if (0.20 * w < x < 0.70 * w) and (0.05 * h < y < 0.15 * h):
            return 1
        # Region IV: éå»NGä¾‹ (å³ä¸Š)
        if (x > 0.73 * w) and (0.05 * h < y < 0.60 * h):
            return 4
        # Region III: 3Dãƒ‡ãƒ¼ã‚¿ (å·¦ä¸‹)
        if (x < 0.22 * w) and (y > 0.60 * h):
            return 3
        # Region II: åŸºç›¤ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ (ä¸­å¤®)
        if (0.22 * w < x < 0.73 * w) and (0.15 * h < y < 0.90 * h):
            return 2

        # ã©ã®é ˜åŸŸã§ã‚‚ãªã„
        return None

    def update(self, gaze_px: Tuple[int, int], w: int, h: int):
        """
        è¦–ç·šåº§æ¨™(gaze_px)ã‚’å—ã‘å–ã‚Šã€è©²å½“ã™ã‚‹é ˜åŸŸã®åˆè¨ˆæ™‚é–“ã‚’æ›´æ–°ã™ã‚‹
        """
        now = time.time()
        if self.last_ts is None:
            self.last_ts = now; return

        # 1ãƒ•ãƒ¬ãƒ¼ãƒ å‰ã®å‘¼ã³å‡ºã—ã‹ã‚‰ã®çµŒéæ™‚é–“ (delta time)
        dt = now - self.last_ts
        self.last_ts = now

        # è¦–ç·šãŒã©ã®é ˜åŸŸã«ã‚ã‚‹ã‹åˆ¤å®š
        r = self.region_of(gaze_px[0], gaze_px[1], w, h)

        # è©²å½“ã™ã‚‹é ˜åŸŸã®åˆè¨ˆæ™‚é–“(stats)ã«dtã‚’åŠ ç®—
        if r is not None and r in self.stats:
            self.stats[r] += dt


def y_intercept(rx_left, rx_right, w):
    """
    ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ç·šå½¢å¤‰æ›ã®ä¿‚æ•°ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«a, ã‚ªãƒ•ã‚»ãƒƒãƒˆbï¼‰ã‚’è¨ˆç®—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼
    (x_screen = a * x_raw + b)
    """
    if abs(rx_right - rx_left) < 1e-9: return 0, 0
    a = w / (rx_right - rx_left)
    b = -(w/2) * (rx_right + rx_left) / (rx_right - rx_left)
    return a, b

# ================== ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆã‚¯ãƒ©ã‚¹ ==================
class HeatmapGenerator:
    """è¦–ç·šãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆãƒ»ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self, width: int, height: int):
        """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ã®Numpyé…åˆ—ã‚’åˆæœŸåŒ–"""
        self.width = width; self.height = height
        self.heatmap_data = np.zeros((height, width), dtype=np.float64)
        self.decay_rate = 0.98 # æ¸›è¡°ç‡
        self.intensity = 5.0 # è¦–ç·šãŒå½“ãŸã£ãŸéš›ã®å¼·åº¦
        self.radius = int(max(width, height) * 0.15) # è¦–ç·šã‚¹ãƒãƒƒãƒˆã®åŠå¾„

    def update(self, gaze_point: Tuple[int, int]):
        """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã«è¦–ç·šä½ç½®(gaze_point)ã‚’è¿½åŠ ï¼ˆã‚¬ã‚¦ã‚¹åˆ†å¸ƒï¼‰"""
        x, y = gaze_point
        if x is None or y is None: return
        x_grid, y_grid = np.ogrid[:self.height, :self.width]
        dist_sq = (x_grid - y)**2 + (y_grid - x)**2
        gauss = self.intensity * np.exp(-dist_sq / (2 * (self.radius / 2)**2))
        self.heatmap_data += gauss

    def decay(self):
        """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å…¨ä½“ã‚’æ™‚é–“çµŒéã§æ¸›è¡°ã•ã›ã‚‹"""
        self.heatmap_data *= self.decay_rate
        self.heatmap_data[self.heatmap_data < 0.01] = 0

    def generate_minimap_image(self, current_gaze_point: Optional[Tuple[int, int]]) -> np.ndarray:
        """ç¾åœ¨ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã¨è¦–ç·šä½ç½®ã‚’æç”»ã—ãŸãƒŸãƒ‹ãƒãƒƒãƒ—ç”»åƒ(ndarray)ã‚’ç”Ÿæˆã™ã‚‹"""
        minimap_bg = np.zeros((self.height, self.width, 3), dtype=np.uint8)
        cv2.rectangle(minimap_bg, (0, 0), (self.width, self.height), (30, 30, 30), -1)

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è‰²ä»˜ã‘(COLORMAP_JET)ã—ã¦æç”»
        if np.max(self.heatmap_data) > 0:
            norm_heatmap = self.heatmap_data / np.max(self.heatmap_data)
            heatmap_8u = (norm_heatmap * 255).astype(np.uint8)
            heatmap_color = cv2.applyColorMap(heatmap_8u, cv2.COLORMAP_JET)
            minimap_bg = cv2.addWeighted(minimap_bg, 0.5, heatmap_color, 0.5, 0)

        # ç¾åœ¨ã®è¦–ç·šä½ç½®ã‚’èµ¤ã„ç‚¹ã§æç”»
        if current_gaze_point:
            cv2.circle(minimap_bg, current_gaze_point, 5, (0, 0, 255), -1)
            cv2.circle(minimap_bg, current_gaze_point, 7, (255, 255, 255), 1)

        cv2.rectangle(minimap_bg, (0, 0), (self.width - 1, self.height - 1), (255, 255, 255), 1)
        return minimap_bg

# ================ Video Processor =================
class VideoProcessor:
    """
    streamlit-webrtc ã® VideoProcessorFactory ã‚¯ãƒ©ã‚¹ã€‚
    Webã‚«ãƒ¡ãƒ©ã®å„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã™ã‚‹æœ¬ä½“ã€‚
    """
    def __init__(self):
        self.est = GazeEstimator(0.5, 0.5) # è¦–ç·šæ¨å®šå™¨
        self.running = False # åˆ†æä¸­ãƒ•ãƒ©ã‚° (UIã®ã€Œåˆ†æé–‹å§‹ã€ãƒœã‚¿ãƒ³ã§True)

        # --- ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ ---
        self.targets = [("å·¦ä¸Š", 0.10, 0.10), ("å³ä¸Š", 0.90, 0.10), ("å·¦ä¸‹", 0.10, 0.90), ("å³ä¸‹", 0.90, 0.90)]
        self.calibrating = False # ã‚­ãƒ£ãƒªãƒ–ä¸­ãƒ•ãƒ©ã‚°
        self.target_idx = 0 # ç¾åœ¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ (0:å·¦ä¸Š, 1:å³ä¸Š, ...)
        self.capture_request = False # ã‚µãƒ³ãƒ—ãƒ«å–å¾—ä¸­ãƒ•ãƒ©ã‚°
        self.capture_buffer: List[Tuple[float, float, int, int]] = [] # ã‚µãƒ³ãƒ—ãƒ«ä¸€æ™‚ä¿å­˜ç”¨
        self.samples: Dict[str, Tuple[float, float, float, float]] = {} # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã”ã¨ã®å¹³å‡ã‚µãƒ³ãƒ—ãƒ«
        self.last_w: Optional[int] = None; self.last_h: Optional[int] = None # æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚º
        self.calib_ready = False # 4ç‚¹ã®ã‚µãƒ³ãƒ—ãƒ«ãŒæƒã£ãŸãƒ•ãƒ©ã‚°

        # --- FPSè¨ˆæ¸¬ ---
        self.fps_start_time = 0; self.fps_frame_count = 0; self.fps = 0.0

        # --- ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— ---
        self.minimap_width = 220; self.minimap_height = 140
        self.heatmap_generator = HeatmapGenerator(self.minimap_width, self.minimap_height)
        self.show_heatmap = True # UIã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§åˆ‡ã‚Šæ›¿ãˆ

        # --- é ˜åŸŸè¨ˆæ¸¬ ---
        self.num_regions = 4
        self.timer = RegionTimer() # é ˜åŸŸã‚¿ã‚¤ãƒãƒ¼

    def start_calibration(self):
        """ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ï¼ˆUIãƒœã‚¿ãƒ³ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ï¼‰"""
        self.calibrating = True; self.calib_ready = False; self.target_idx = 0
        self.capture_request = False; self.capture_buffer.clear(); self.samples.clear()

    def request_sample(self):
        """ç¾åœ¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒ«å–å¾—ã‚’è¦æ±‚ï¼ˆUIãƒœã‚¿ãƒ³ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ï¼‰"""
        if self.calibrating and self.target_idx < len(self.targets):
            self.capture_request = True; self.capture_buffer.clear()

    def skip_target(self):
        """ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ç¾åœ¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—"""
        if self.calibrating and self.target_idx < len(self.targets):
            self.target_idx += 1; self.capture_request = False; self.capture_buffer.clear()
            if self.target_idx >= len(self.targets): self.calib_ready = True

    def reset_calibration(self):
        """ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆUIãƒœã‚¿ãƒ³ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ï¼‰"""
        self.start_calibration()

    def _compute_and_apply_calibration(self) -> Tuple[bool, str]:
        """
        åé›†ã—ãŸ4ç‚¹ã®ã‚µãƒ³ãƒ—ãƒ«(self.samples)ã‹ã‚‰ã€è¦–ç·šã®ã‚¹ã‚±ãƒ¼ãƒ«ã¨ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è¨ˆç®—ã—ã€
        GazeEstimatorã«é©ç”¨ã™ã‚‹ã€‚
        """
        need = {"å·¦ä¸Š", "å³ä¸Š", "å·¦ä¸‹", "å³ä¸‹"}
        if not need.issubset(self.samples.keys()): return False, "å››éš…ã®ã‚µãƒ³ãƒ—ãƒ«ãŒæƒã£ã¦ã„ã¾ã›ã‚“ã€‚"
        if self.last_w is None or self.last_h is None: return False, "ã‚«ãƒ¡ãƒ©ã‹ã‚‰æ˜ åƒãŒå–å¾—ã§ãã¦ã„ã¾ã›ã‚“ã€‚"

        # å„ç‚¹ã®å¹³å‡å€¤ã‚’å–å¾—
        rx_lu, ry_lu, ex_lu, ey_lu = self.samples["å·¦ä¸Š"]; rx_ru, ry_ru, ex_ru, ey_ru = self.samples["å³ä¸Š"]
        rx_ld, ry_ld, ex_ld, ey_ld = self.samples["å·¦ä¸‹"]; rx_rd, ry_rd, ex_rd, ey_rd = self.samples["å³ä¸‹"]

        # raw_vecã®Xæ–¹å‘ï¼ˆå·¦å³ï¼‰ã®ç¯„å›²ã‚’è¨ˆç®—
        rx_left = (rx_lu + rx_ld) / 2.0; rx_right = (rx_ru + rx_rd) / 2.0
        # raw_vecã®Yæ–¹å‘ï¼ˆä¸Šä¸‹ï¼‰ã®ç¯„å›²ã‚’è¨ˆç®—
        ry_top = (ry_lu + ry_ru) / 2.0; ry_bottom = (ry_ld + ry_rd) / 2.0

        w, h = self.last_w, self.last_h
        dx = rx_right - rx_left; dy = ry_bottom - ry_top

        if abs(dx) < 1e-9 or abs(dy) < 1e-9: return False, "å·®åˆ†ãŒå°ã•ã™ãã¾ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ã‚’å–ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚"

        # ã‚¹ã‚±ãƒ¼ãƒ«ã¨ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è¨ˆç®—
        scale_x, offx = y_intercept(rx_left, rx_right, w)
        scale_y, offy = y_intercept(ry_top, ry_bottom, h) # â€»y_interceptã¯Yè»¸ï¼ˆä¸‹å‘ãæ­£ï¼‰ã§ã‚‚ä½¿ãˆã‚‹

        # GazeEstimatorã«å€¤ã‚’è¨­å®š
        self.est.set_calibration_values(
            rx_left=rx_left, rx_right=rx_right, ry_top=ry_top, ry_bottom=ry_bottom,
            offx_px=float(offx), offy_px=float(offy), base_w=w, base_h=h)

        return True, (f"é©ç”¨ OK: dx={dx:.6g}, dy={dy:.6g}, offx={offx:.1f}px, offy={offy:.1f}px, "
                      f"scale_x={scale_x:.1f}, scale_y={scale_y:.1f} @ {w}x{h}, samples={rx_left, rx_right, ry_top, ry_bottom}")

    def _draw_guides(self, frame):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã«4é ˜åŸŸã®ã‚¬ã‚¤ãƒ‰ï¼ˆç·‘è‰²ã®å››è§’ï¼‰ã‚’æç”»ã™ã‚‹"""
        h, w, _ = frame.shape; color = (0, 255, 0); thickness = 2
        # Region I
        r1_x1, r1_y1 = int(0.20 * w), int(0.05 * h); r1_x2, r1_y2 = int(0.70 * w), int(0.15 * h)
        cv2.rectangle(frame, (r1_x1, r1_y1), (r1_x2, r1_y2), color, thickness)
        cv2.putText(frame, "I", (r1_x1 + 5, r1_y1 + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
        # Region II
        r2_x1, r2_y1 = int(0.22 * w), int(0.15 * h); r2_x2, r2_y2 = int(0.73 * w), int(0.90 * h)
        cv2.rectangle(frame, (r2_x1, r2_y1), (r2_x2, r2_y2), color, thickness)
        cv2.putText(frame, "II", (r2_x1 + 5, r2_y1 + 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)
        # Region III
        r3_x1, r3_y1 = int(0), int(0.60 * h); r3_x2, r3_y2 = int(0.22 * w), int(h)
        cv2.rectangle(frame, (r3_x1, r3_y1), (r3_x2, r3_y2), color, thickness)
        cv2.putText(frame, "III", (r3_x1 + 5, r3_y1 + 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)
        # Region IV
        r4_x1, r4_y1 = int(0.73 * w), int(0.05 * h); r4_x2, r4_y2 = int(w), int(0.60 * h)
        cv2.rectangle(frame, (r4_x1, r4_y1), (r4_x2, r4_y2), color, thickness)
        cv2.putText(frame, "IV", (r4_x1 + 5, r4_y1 + 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)

    def _draw_calib_target(self, frame):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆç·‘è‰²ã®å††ï¼‰ã‚’æç”»ã™ã‚‹"""
        if not self.calibrating: return; h, w, _ = frame.shape
        if self.calib_ready or self.target_idx >= len(self.targets): return
        name, nx, ny = self.targets[self.target_idx]; px, py = int(nx * w), int(ny * h)
        cv2.circle(frame, (px, py), 16, (0, 255, 0), 3); cv2.circle(frame, (px, py), 6, (0, 255, 255), -1)

    def draw_overlay(self, frame: np.ndarray, eye_px, end_px):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¦–ç·šï¼ˆç›®ã®ä¸­å¿ƒã¨è¦–ç·šã®å…ˆï¼‰ã‚’æç”»ã™ã‚‹"""
        if eye_px and end_px:
            cv2.circle(frame, eye_px, 6, (255, 255, 255), -1) # ç›®ã®ä¸­å¿ƒ(ç™½)
            cv2.circle(frame, end_px, 6, (0, 255, 255), -1) # è¦–ç·šã®å…ˆ(é»„)
            # è»Œè·¡ã‚’æç”»
            for i in range(8):
                t = i / (8 - 1); x = int(eye_px[0] + t * (end_px[0] - eye_px[0])); y = int(eye_px[1] + t * (end_px[1] - eye_px[1]))
                cv2.circle(frame, (x, y), max(2, 6 - i), (0, 200, 255), -1)
        return frame

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        """
        WebRTCã‹ã‚‰æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãŒæ¥ã‚‹ãŸã³ã«å‘¼ã³å‡ºã•ã‚Œã‚‹ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†é–¢æ•°
        """
        img = frame.to_ndarray(format="bgr24")
        img = cv2.flip(img, 1) # å·¦å³åè»¢
        h, w, _ = img.shape
        self.last_w, self.last_h = img.shape[1], img.shape[0]

        # 1. è¦–ç·šæ¨å®š
        ok, eye_px, end_px, raw_vec = self.est.estimate(img)

        # 2. FPSè¨ˆæ¸¬
        if self.fps_start_time == 0: self.fps_start_time = time.time()
        self.fps_frame_count += 1; elapsed_time = time.time() - self.fps_start_time
        if elapsed_time >= 1.0:
            self.fps = self.fps_frame_count / elapsed_time; self.fps_frame_count = 0; self.fps_start_time = time.time()

        # 3. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚µãƒ³ãƒ—ãƒ«åé›†ä¸­
        if self.calibrating and self.capture_request and ok and raw_vec:
            self.capture_buffer.append((raw_vec[0], raw_vec[1], eye_px[0], eye_px[1]))
            # 15ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ãŸã¾ã£ãŸã‚‰å¹³å‡ã‚’ã¨ã£ã¦ä¿å­˜
            if len(self.capture_buffer) >= 15:
                avg = np.mean(self.capture_buffer, axis=0); name, _, _ = self.targets[self.target_idx]
                self.samples[name] = tuple(float(v) for v in avg)
                self.capture_request = False; self.capture_buffer.clear(); self.target_idx += 1
                if self.target_idx >= len(self.targets): self.calib_ready = True # 4ç‚¹å®Œäº†

        # 4. åˆ†æä¸­ (running=True) ã®ã¿ã‚¿ã‚¤ãƒãƒ¼ã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ›´æ–°
        current_minimap_gaze = None
        if self.running and ok and end_px:
            # 4-1. é ˜åŸŸã‚¿ã‚¤ãƒãƒ¼ã‚’æ›´æ–°
            self.timer.update(end_px, w, h)

            # 4-2. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ›´æ–°
            if self.show_heatmap:
                # ç”»é¢åº§æ¨™(end_px)ã‚’ãƒŸãƒ‹ãƒãƒƒãƒ—åº§æ¨™ã«å¤‰æ›
                minimap_x = int((end_px[0] / w) * self.minimap_width); minimap_y = int((end_px[1] / h) * self.minimap_height)
                current_minimap_gaze = (minimap_x, minimap_y)
                self.heatmap_generator.update(current_minimap_gaze)

        # 5. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆãƒŸãƒ‹ãƒãƒƒãƒ—ï¼‰ã®æç”»
        if self.show_heatmap:
            self.heatmap_generator.decay() # æ¸›è¡°
            minimap_image = self.heatmap_generator.generate_minimap_image(current_minimap_gaze)
            # ç”»é¢å³ä¸‹ã«åˆæˆ
            margin = 10; map_h, map_w, _ = minimap_image.shape; y_offset = h - map_h - margin; x_offset = w - map_w - margin
            img[y_offset:y_offset + map_h, x_offset:x_offset + map_w] = minimap_image

        # 6. ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆè¦–ç·šã€ã‚¬ã‚¤ãƒ‰ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰ã‚’æç”»
        img = self.draw_overlay(img, eye_px if ok else None, end_px if ok else None)
        self._draw_guides(img)
        self._draw_calib_target(img) # ã‚­ãƒ£ãƒªãƒ–ä¸­ã®ã¿æç”»ã•ã‚Œã‚‹

        # 7. FPSã‚’æç”»
        fps_text = f"FPS: {self.fps:.1f}"; cv2.putText(img, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

        # 8. å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¿”ã™
        return av.VideoFrame.from_ndarray(img, format="bgr24")

    def apply_calibration(self) -> Tuple[bool, str]:
        """UIã‹ã‚‰å‘¼ã°ã‚Œã€ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨ˆç®—ãƒ»é©ç”¨ã‚’å®Ÿè¡Œã™ã‚‹"""
        return self._compute_and_apply_calibration()

def get_region_labels(num_regions: int) -> Dict[int, str]:
    """é ˜åŸŸIDã«å¯¾å¿œã™ã‚‹ãƒ©ãƒ™ãƒ«(I, II, III, IV)ã‚’è¿”ã™"""
    if num_regions == 4:
        return {1: "I: ã‚¨ãƒ©ãƒ¼æ–‡å­—", 2: "II: åŸºç›¤ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦", 3: "III: 3Dãƒ‡ãƒ¼ã‚¿ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦", 4: "IV: éå»ã®NGä¾‹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦"}
    if num_regions == 3: # éå»ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ç”¨
        return {1: "â‘  å·¦", 2: "â‘¡ ä¸­å¤®", 3: "â‘¢ å³"}
    return {i: f"ã‚¨ãƒªã‚¢ {i}" for i in range(1, num_regions + 1)}


# ================= åˆ†æãƒ¬ãƒãƒ¼ãƒˆ =================
def generate_analysis_report(
    actual_stats: Dict[int, float],
    standard_durations: Dict[int, float],
    labels: Dict[int, str]
) -> Tuple[str, str]:
    """
    æ¨™æº–å‹•ä½œï¼ˆåˆè¨ˆæ™‚é–“ï¼‰ã¨åˆ†æå‹•ä½œï¼ˆåˆè¨ˆæ™‚é–“ï¼‰ã‚’æ¯”è¼ƒã—ã€
    "æ¨™æº–å‹•ä½œï¼š..." ã¨ "åˆ†æå‹•ä½œï¼š..." ã®2ã¤ã®æ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    standard_parts = []
    analysis_parts = []

    # åŸºæº–ã®é †ç•ª (I, II, III, IV) ã§å‡¦ç†
    for region_id in sorted(standard_durations.keys()):
        label_name = labels.get(region_id, f"Region {region_id}").split(":")[0] # "I: ã‚¨ãƒ©ãƒ¼æ–‡å­—" -> "I"
        standard_sec = standard_durations.get(region_id, 0.0)
        actual_sec = actual_stats.get(region_id, 0.0)

        # 1. æ¨™æº–å‹•ä½œæ–‡å­—åˆ—ã®ä½œæˆ (ä¾‹: "I(2ç§’)")
        standard_parts.append(f"{label_name}({standard_sec:.0f}ç§’)")

        # 2. åˆ†æå‹•ä½œæ–‡å­—åˆ—ã®ä½œæˆ (ä¾‹: "I(2.0ç§’: â—¯ ...)")
        tolerance = 1.0 # è¨±å®¹èª¤å·®1ç§’

        if actual_sec == 0:
            symbol, comment = "Ã—", "è¦‹ã¦ã„ãªã„å¯èƒ½æ€§ãŒé«˜ã„ã§ã™"
        elif abs(actual_sec - standard_sec) <= tolerance:
            symbol, comment = "â—¯", "æ¨™æº–å‹•ä½œé€šã‚Šã«è¦‹ã¦ã„ã¾ã™"
        elif actual_sec < standard_sec:
            symbol, comment = "â–³", "è¦‹ã¦ã„ã‚‹æ™‚é–“ãŒçŸ­ã„ã§ã™"
        else: # actual_sec > standard_sec
            symbol, comment = "â–³", "è¦‹ã¦ã„ã‚‹æ™‚é–“ãŒé•·ã„ã§ã™"

        analysis_parts.append(f"{label_name}({actual_sec:.1f}ç§’: {symbol} {comment})")

    # "â†’"ã§é€£çµ
    standard_str = "â†’".join(standard_parts)
    analysis_str = "â†’".join(analysis_parts)

    return standard_str, analysis_str

# ================= PDF =================
JAPANESE_FONT_PATH = "ipaexg00401/ipaexg.ttf" # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãƒ‘ã‚¹
STANDARD_DURATIONS = {1: 2.0, 2: 4.0, 3: 3.0, 4: 3.0} # æ¨™æº–å‹•ä½œã®ç§’æ•° (I:2s, II:4s, ...)

def create_history_pdf(history_data: list) -> io.BytesIO:
    """
    å±¥æ­´ãƒ‡ãƒ¼ã‚¿(history_data)ã‚’å—ã‘å–ã‚Šã€PDFãƒ•ã‚¡ã‚¤ãƒ«(BytesIO)ã‚’ç”Ÿæˆã™ã‚‹
    """
    pdf = FPDF()
    pdf.add_page()
    pdf.add_font('Japanese', '', JAPANESE_FONT_PATH, uni=True) # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ç™»éŒ²
    pdf.set_font('Japanese', '', 16)
    pdf.cell(0, 10, "ã‚¢ã‚¤ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°åˆ†æå±¥æ­´", 0, 1, 'C')
    pdf.ln(5)

    # PDFã®å…ˆé ­ã«ã€ŒåŸºæº–ï¼ˆæ¨™æº–å‹•ä½œï¼‰ã€ã‚’è¨˜è¼‰
    standard_labels_for_pdf = get_region_labels(4)
    standard_str, _ = generate_analysis_report({}, STANDARD_DURATIONS, standard_labels_for_pdf)
    pdf.set_font('Japanese', '', 12)
    pdf.set_fill_color(245, 245, 245)
    pdf.cell(35, 8, "åŸºæº– (æ¨™æº–å‹•ä½œ):", border=0, fill=False)
    pdf.multi_cell(0, 8, standard_str, border=1, fill=True)
    pdf.ln(5)

    # å±¥æ­´ã‚’1ä»¶ãšã¤å‡¦ç† (reversedã§æ–°ã—ã„é †ã«)
    for item in reversed(history_data):
        stats = item.get("stats", {})
        num_regions = len(stats)
        if num_regions == 0: continue

        labels = get_region_labels(num_regions) # å±¥æ­´ã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³æ•°ã«åˆã‚ã›ãŸãƒ©ãƒ™ãƒ«ã‚’å–å¾—

        pdf.set_font('Japanese', '', 12)
        pdf.cell(0, 10, f"è¨˜éŒ²æ—¥æ™‚: {item['time']}", 0, 1)
        pdf.set_font('Japanese', '', 10)
        pdf.set_fill_color(240, 240, 240)

        # --- å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æç”» ---
        cell_width = 60; cell_height = 8
        pdf.cell(cell_width, cell_height, "ç¯„å›²", border=1, fill=True, align='C')

        is_4_region_history = (num_regions == 4)
        if is_4_region_history:
            pdf.set_font('Japanese', '', 9) # 3åˆ—ã«ã™ã‚‹ãŸã‚ãƒ•ã‚©ãƒ³ãƒˆã‚’å°‘ã—å°ã•ã
            pdf.cell(cell_width, cell_height, "æ¨™æº–å‹•ä½œ (ç§’)", border=1, fill=True, align='C')
            pdf.cell(cell_width, cell_height, "åˆè¨ˆç§’", border=1, fill=True, align='C')
            pdf.set_font('Japanese', '', 10)
        else:
             pdf.cell(cell_width, cell_height, "åˆè¨ˆç§’", border=1, fill=True, align='C')
        pdf.ln()

        for i in sorted(stats.keys()):
            pdf.cell(cell_width, cell_height, labels.get(i, f"Region {i}"), border=1)
            if is_4_region_history:
                standard_sec = STANDARD_DURATIONS.get(i, 0.0)
                pdf.cell(cell_width, cell_height, f"{standard_sec:.1f}", border=1, align='C')
            pdf.cell(cell_width, cell_height, f"{stats.get(i, 0.0):.1f}", border=1, align='C')
            pdf.ln()
        # --- å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ã“ã“ã¾ã§ ---

        # 4é ˜åŸŸã®å±¥æ­´ã®å ´åˆã€åˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆâ—¯â–³Ã—ï¼‰ã‚‚è¨˜è¼‰
        if num_regions == 4:
            _, analysis_str = generate_analysis_report(stats, STANDARD_DURATIONS, labels)
            pdf.set_font('Japanese', '', 10)
            pdf.cell(30, 8, "åˆ†æå‹•ä½œ:", border=0)
            pdf.set_fill_color(250, 250, 250)
            pdf.multi_cell(0, 8, analysis_str, border=1, fill=True)

        pdf.ln(10)

    # PDFã‚’BytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦è¿”ã™
    return io.BytesIO(pdf.output())


# ================= Streamlit UI ==================
st.set_page_config(page_title="åŸºæ¿å®Ÿè£…çŠ¶æ…‹ã®ç¢ºèªä½œæ¥­ ã‚¢ã‚¤ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("åŸºæ¿å®Ÿè£…çŠ¶æ…‹ã®ç¢ºèªä½œæ¥­ ã‚¢ã‚¤ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– ---
# å±¥æ­´ãƒ‡ãƒ¼ã‚¿
if "history" not in st.session_state: st.session_state.history = []
# åˆ†æä¸­ãƒ•ãƒ©ã‚°
if "running" not in st.session_state: st.session_state.running = False
# é ˜åŸŸæ•°ã¯4ã§å›ºå®š
st.session_state.num_regions = 4
# ç¾åœ¨ã®åˆ†æçµæœï¼ˆåˆè¨ˆæ™‚é–“ï¼‰
if "current_stats" not in st.session_state or len(st.session_state.current_stats) != 4:
    st.session_state.current_stats = {i: 0.0 for i in range(1, 4 + 1)}

# é ˜åŸŸãƒ©ãƒ™ãƒ«ã‚’å–å¾—
region_labels = get_region_labels(4)

# --- ç”»é¢ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ (2ã‚«ãƒ©ãƒ ) ---
cols = st.columns([1, 1])

# --- ã‚«ãƒ©ãƒ 1: ã‚«ãƒ¡ãƒ©ã¨æ“ä½œãƒœã‚¿ãƒ³ ---
with cols[0]:
    st.subheader("ã‚«ãƒ¡ãƒ©æ˜ åƒ")
    show_heatmap_toggle = st.checkbox("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤º", value=True)

    # WebRTCã‚¹ãƒˆãƒªãƒ¼ãƒãƒ¼ã®è¨­å®š
    rtc_config = RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]})
    ctx = webrtc_streamer(
        key="eyetracking",
        mode=WebRtcMode.SENDRECV,
        video_processor_factory=VideoProcessor, # ä¸Šã§å®šç¾©ã—ãŸVideoProcessorã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨
        async_processing=True,
        rtc_configuration=rtc_config,
        media_stream_constraints={"video": True, "audio": False},
    )

    # VideoProcessorã«UIã®çŠ¶æ…‹ã‚’æ¸¡ã™
    if ctx.state.playing and ctx.video_processor:
        ctx.video_processor.show_heatmap = show_heatmap_toggle
        ctx.video_processor.num_regions = 4 # å¸¸ã«4é ˜åŸŸ

    # --- æ“ä½œãƒœã‚¿ãƒ³ ---
    c1, c2, c3 = st.columns(3)
    with c1:
        # ã€Œåˆ†æé–‹å§‹ã€ãƒœã‚¿ãƒ³
        if st.button("åˆ†æé–‹å§‹", use_container_width=True):
            if ctx.state.playing:
                st.session_state.running = True
                if ctx.video_processor:
                    ctx.video_processor.num_regions = 4
                    ctx.video_processor.running = True
                    ctx.video_processor.timer = RegionTimer() # ã‚¿ã‚¤ãƒãƒ¼ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.current_stats = ctx.video_processor.timer.stats.copy()
            else: st.warning("ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã¦ä¸‹ã•ã„")
    with c2:
        # ã€Œåˆ†æçµ‚äº†ã€ãƒœã‚¿ãƒ³
        if st.button("åˆ†æçµ‚äº†", use_container_width=True):
            if ctx.state.playing and st.session_state.running:
                st.session_state.running = False
                if ctx.video_processor:
                    ctx.video_processor.running = False
                    stats = ctx.video_processor.timer.stats
                    st.session_state.current_stats = stats
                    # å±¥æ­´ã«ç¾åœ¨ã®åˆ†æçµæœã‚’è¿½åŠ 
                    st.session_state.history.append({
                        "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "stats": stats.copy(),
                    })
            else: st.warning("åˆ†æãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    with c3:
        # ã€Œã‚­ãƒ£ãƒªãƒ–é–‹å§‹ã€ãƒœã‚¿ãƒ³
        if st.button("ã‚­ãƒ£ãƒªãƒ–é–‹å§‹", use_container_width=True):
            if ctx.state.playing:
                ctx.video_processor.start_calibration()
                st.success("ã‚­ãƒ£ãƒªãƒ–ã‚’é–‹å§‹ã€‚å„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’è¦‹ã¦ã€ã‚µãƒ³ãƒ—ãƒ«å–å¾—ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            else: st.warning("ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã¦ä¸‹ã•ã„")

    # --- ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ“ä½œUI (ã‚­ãƒ£ãƒªãƒ–ä¸­ã®ã¿è¡¨ç¤º) ---
    if ctx.state.playing and ctx.video_processor and ctx.video_processor.calibrating:
        d1, d2, d3 = st.columns(3)
        with d1:
            # ã€Œã‚µãƒ³ãƒ—ãƒ«å–å¾—ã€ãƒœã‚¿ãƒ³
            if st.button("ã‚µãƒ³ãƒ—ãƒ«å–å¾—ï¼ˆ15fï¼‰", use_container_width=True):
                if not ctx or not ctx.state.playing: st.warning("ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã¦ä¸‹ã•ã„")
                elif not ctx.video_processor or not ctx.video_processor.calibrating: st.warning("ã¾ãšã€ã‚­ãƒ£ãƒªãƒ–é–‹å§‹ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„")
                else:
                    ctx.video_processor.request_sample(); st.info("å–å¾—ä¸­â€¦ï¼ˆ15ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰")
        with d2:
            # ã€Œãƒªã‚»ãƒƒãƒˆã€ãƒœã‚¿ãƒ³
            if st.button("ãƒªã‚»ãƒƒãƒˆ"): ctx.video_processor.reset_calibration()
        with d3:
            # ã€Œé©ç”¨ã€ãƒœã‚¿ãƒ³
            if st.button("é©ç”¨"):
                ok, msg = ctx.video_processor.apply_calibration()
                if ok:
                    st.success(msg)
                else:
                    st.error(msg)

        # å–å¾—çŠ¶æ³ã®è¡¨ç¤º
        order = [t[0] for t in ctx.video_processor.targets]
        marks = ["âœ…" if name in ctx.video_processor.samples else "â¬œ" for name in order]
        st.caption("å–å¾—çŠ¶æ³: " + " | ".join(f"{m} {n}" for m, n in zip(marks, order)))
        if ctx.video_processor.calib_ready: st.success("å››éš…ã®ã‚µãƒ³ãƒ—ãƒ«ãŒæƒã„ã¾ã—ãŸã€‚ã€é©ç”¨ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        elif ctx.video_processor.target_idx < len(order): st.caption(f"æ¬¡ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {order[ctx.video_processor.target_idx]}")

    # åˆ†æä¸­ã€UIã®è¡¨ç¤ºã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
    if ctx.state.playing and ctx.video_processor and st.session_state.running:
        st.session_state.current_stats = ctx.video_processor.timer.stats

# --- ã‚«ãƒ©ãƒ 2: åˆ†æçµæœ ---
with cols[1]:
    st.subheader("ä»Šå›ã®åˆ†æçµæœ (åˆè¨ˆæ™‚é–“)")
    cur = st.session_state.current_stats

    # --- åˆ†æçµæœãƒ†ãƒ¼ãƒ–ãƒ« (3åˆ—) ---
    table_data = {
        "ç¯„å›²": [],
        "æ¨™æº–å‹•ä½œ (ç§’)": [],
        "åˆè¨ˆç§’": []
    }
    for region_id in sorted(STANDARD_DURATIONS.keys()):
        label = region_labels.get(region_id, f"ã‚¨ãƒªã‚¢ {region_id}")
        standard_sec = STANDARD_DURATIONS.get(region_id, 0.0)
        actual_sec = cur.get(region_id, 0.0)

        table_data["ç¯„å›²"].append(label)
        table_data["æ¨™æº–å‹•ä½œ (ç§’)"].append(f"{standard_sec:.1f}")
        table_data["åˆè¨ˆç§’"].append(f"{actual_sec:.1f}")

    st.table(table_data)
    # --- ãƒ†ãƒ¼ãƒ–ãƒ«ã“ã“ã¾ã§ ---


    # --- å‹•ä½œæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ (ãƒ†ã‚­ã‚¹ãƒˆ) ---
    st.markdown("---")
    st.subheader("å‹•ä½œæ¯”è¼ƒ")
    standard_str, analysis_str = generate_analysis_report(cur, STANDARD_DURATIONS, region_labels)
    st.text("æ¨™æº–å‹•ä½œï¼š")
    st.info(standard_str)
    st.text("åˆ†æå‹•ä½œï¼š")
    st.success(analysis_str)
    # --- ãƒ¬ãƒãƒ¼ãƒˆã“ã“ã¾ã§ ---

    st.markdown("---")

    # --- JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ ---
    json_str = json.dumps({
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_stats": {
            region_labels.get(i, f"Region {i}"): {"duration_sec": f"{cur.get(i, 0.0):.1f}"}
            for i in range(1, 4 + 1)
        },
        "analysis_report": {
            "standard": standard_str,
            "actual": analysis_str
        }
    }, ensure_ascii=False, indent=2)
    st.download_button(
        label="çµæœã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=json_str,
        file_name=f"gaze_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json",
    )

# --- å±¥æ­´ã‚»ã‚¯ã‚·ãƒ§ãƒ³ (ã‚«ãƒ©ãƒ ã®å¤–) ---
st.markdown("---")
st.subheader("å±¥æ­´")

if not st.session_state.history:
    st.info("ã¾ã å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã€åˆ†æé–‹å§‹ã€â†’ã€åˆ†æçµ‚äº†ã€ã§è¿½åŠ ã•ã‚Œã¾ã™ã€‚")
else:
    # --- PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ ---
    if not os.path.exists(JAPANESE_FONT_PATH):
        st.error(f"æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {JAPANESE_FONT_PATH}\n"
                 "PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
    else:
        pdf_data = create_history_pdf(st.session_state.history) # PDFç”Ÿæˆ
        st.download_button(
            label="ğŸ“ˆ å…¨ã¦ã®å±¥æ­´ã‚’PDFã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=pdf_data,
            file_name=f"gaze_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
            mime="application/pdf",
        )

    # --- å±¥æ­´ã‚’ä¸€ä»¶ãšã¤è¡¨ç¤º ---
    for item in reversed(st.session_state.history):
        with st.expander(f"{item['time']} ã®çµæœ"):
            stats = item.get("stats", {})
            num_regions_in_history = len(stats)
            if num_regions_in_history == 0: continue

            history_labels = get_region_labels(num_regions_in_history)

            # --- å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ« ---
            history_table_data = {
                "ç¯„å›²": [],
                "æ¨™æº–å‹•ä½œ (ç§’)": [],
                "åˆè¨ˆç§’": []
            }
            is_4_region_history = (num_regions_in_history == 4)

            for i in sorted(stats.keys()):
                label = history_labels.get(i, f"ã‚¨ãƒªã‚¢ {i}")
                actual_sec = stats.get(i, 0.0)

                history_table_data["ç¯„å›²"].append(label)
                history_table_data["åˆè¨ˆç§’"].append(f"{actual_sec:.1f}")

                if is_4_region_history:
                    standard_sec = STANDARD_DURATIONS.get(i, 0.0)
                    history_table_data["æ¨™æº–å‹•ä½œ (ç§’)"].append(f"{standard_sec:.1f}")
                else:
                    pass

            if not is_4_region_history:
                del history_table_data["æ¨™æº–å‹•ä½œ (ç§’)"]

            st.table(history_table_data)
            # --- å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ã“ã“ã¾ã§ ---

            # --- å±¥æ­´ãƒ¬ãƒãƒ¼ãƒˆ (ãƒ†ã‚­ã‚¹ãƒˆ) ---
            if num_regions_in_history == 4:
                _, analysis_str = generate_analysis_report(stats, STANDARD_DURATIONS, history_labels)
                st.text("åˆ†æå‹•ä½œï¼š")
                st.info(analysis_str)
            # --- å±¥æ­´ãƒ¬ãƒãƒ¼ãƒˆã“ã“ã¾ã§ ---